# LeetCode ML

## Machine Learning Model

그럼 무엇이 머신 러닝 모델인가?

>> 머신 러닝 알고리즘은 데이터 안에 있는 내재된 관계를 파악하는 과정이다. 머신 러닝 알고리즘의 결과물이 머신 러닝 모델이라고 하고,
>> 이는 함수 F로서 주어진 입력에 대해 특정의 결과값은 제공한다. 미리정의되거나 고정된 함수와는 달리 머신 러닝 모델은 과거의 자료로
>> 부터 유도된다. 그러므로 다른 자료가 제공되면 머신 러닝 모델의 결과값은 변하게 되고 즉 머신 러닝 모델이 변하게 된다.

머신 러닝의 과제는 방대한 매핑 공간에서 특정 함수를 배우는 과정이다.

## Supervised VS. Unsupervised

어떤 머신 러닝 문제에서든 우리는 데이터 셋트로부터 시작한다. 이는 `샘플들`의 집합이다. 각각의 샘플은 `속성`의 집합으로 표현된다.

지도 학습의 경우, 샘플은 목표 속성 y, 진리값으로 알려진 것을 가지고 있다. 여기서 과제는 목표 속성이 아닌 값들 X에 대해 목표값을
근사해주는 F(X)~y 인 함수를 배우는 것이다. 목표값 y는 학습 과정을 가이드하는 선생의 역할을 하여 학습 과정의 결과에 대한 벤치마크
정보를 제공한다. 그러므로 이 과정은 지도 학습이라고 불리운다.

지도 학습과는 달리, 우리는 비지도 학습에서는 진리값을 갖고 있지 않다. 이 경우 미리 정의된 진리값을 벤치 마크로 사용하지 않고
데이터로 부터 내재된 패턴이나 규칙을 찾아내야 한다. `Clustering`: 주어진 데이터 세트에 대해 각 샘플들의 동일성에 기반하여
각 샘플을 특정 그룹으로 분류할 수 있다. `Association`: 주어진 데이터 세트에 대해서 연관 작업은 샘플의 속성들간에 숨겨진
관계들을 찾아내는 것이다.

데이터 세트의 크기가 방대하고 레이블이 된 샘플의 개수가 작은 경우에 우리는 지도학습과 비지도 학습 모두를 사용할 수 있다. 이 경우
우리는 이를 준지도 학습이라 한다. 예를 들어 이미지의 레이블을 작성해 하는데, 오직 10%만 레이블이 있다고 가정해 보자. 이경우
작은 데이터 세트에서 모델을 학습시켜 남은 샘플들의 레이블을 추측하게 하는 것이다. 이경우 작은 데이터로 만들어진 모델이 잘 적용될
지 의문을 가질 수 있다. 따라서 더 나은 전략은 이미지들의 클러스터링을 활용하여 작은 그룹들로 나누고 각각에 그룹에 대해 지도 학습을
적용하는 것이다. 이경우 지도 학습은 더 나은 결과를 보여줄 수 있다.

## Classfication VS. Regression

모델의 결과값이 연속적인 수치인 경우 이를 회귀 모델이라고 하고, 연속적인 수치가 아닌 경우에는 분류 모델이라고 한다.

$$ F(M[H][W]) = 1|0, where M[i][j] \in [0, 255], 0<i<H, 0<j<W $$

$$ F(T) = p, where p \in R $$

이 두 가지 종류의 모델은 실제 문제에 경우 명확하게 구분하기 쉽지 않다. 예를 들어 분류 문제의 경우, 각 경우에 해당하는 확률로
정답을 지정하게 되면 이는 회기 모델이 되고 이를 Logistic Regression이라고 한다.

## Data, Data, Data!

머신 러닝 작업 흐름의 최종 목표는 머신 러닝 모델을 구축하는 것이다. 또한 이 모델은 데이터로부터 얻어지게 된다. 따라서 데이터는
모델이 이룰수 있는 성과의 상한값을 결정하게 된다. 이를 해결하기 위해서는 좋은 품질의 데이터가 있어야 하는데, 이는 프라이버시 및
우리의 이해의 한계로 인해 구하기가 쉽지 않다. 실제 문제에서는 어떤 머신 러닝 모델을 구축하더라도 만약 데이터에 너무 많은 노이즈가
있거나 현실과 너무 동떨어진 경우, 모델은 어떤 것도 배울 수 없을 것이다.

## Machine Learning Workflow

>> 머신 러닝 작업 흐름은 데이터를 기반으로 돌아간다.

![Machine Learning Workflow](https://assets.leetcode.com/uploads/2018/11/25/ml_workflow.png)

1. 머신 러닝 문제의 타입을 결정한다. 지도학습인가 비지도 학습인가?
1. 지도 학습인 경우 결과값을 통해 모델 유형을 결정한다. 분류 문제인가 회귀 문제인가?
1. 위의 내용들이 정해지면 데이터를 원하는 형태로 변환하는 과정인 feature engineering을 수행한다.
    - 거의 모든 경우에 자료를 훈련과 테스트 셋으로 나누는 작업을 한다.
    - 최초 자료는 많은 경우 손실된 값을 가지고 있고 이를 해결하기 위해 다양한 전략을 이용한다. [ ] imputation 작업 익히기
    - 데이터 셋은 항목 속성의 값을 가지고 있는데 이를 수치 속성의 값을 변환하기 위해 encoding 작업이 필요하다.
1. 데이터가 준비되면 여러 머신 러닝 알고리즘 중에 하나를 선택해서 훈련 데이터 셋으로 학습시킨다. (training process)
1. 훈련 과정이 끝나면 테스트 셋으로 확인을 한다. (testing process)
1. 다른 파라미터로 모델을 설정한 후 다시 훈련과 테스트를 하는데, 이러한 과정을 반복하면서 최종적으로 성능을 향상시킬 수 있다. (hyperparameter tuning)

## Underfitting VS. Overfitting

지도 학습의 중요한 요소는 **일반화**인데 이는 훈련 데이터로부터 학습된 모델이 보지 못한 데이터에 대해서도 원하는 속성을 예측할수 있는
지를 측정하는 것이다. 우리가 모델이 underfitting 혹은 overfitting이라고 말할 때, 이는 모델이 보지 못한 자료에 대해서 일반화되지
않았다는 것을 의미한다.

1) 훈련 자료가 현실 자료와 달라서 모델이 보지 못한 자료에 잘 맞지 않는다. 2) 우리가 수집한 자료가 노이즈와 에러를 많이 가지고 있다.

`Underfitting`: 모델이 훈련 자료에 잘 들어맞지 않는다. 이는 모델이 너무 많이 간략화되어 있어서 데이터 안에 있는 숨어있는 상관 관계를
파악하지 못하는 경우이다. 이를 해결하기 위해서는 좀 더 복잡한 모델을 사용해야 한다.

`Overfitting`: 모델이 훈련 자료에 너무 잘 들어맞아 보지 못한 자료에 일반화 되지 못하는 경우이다. 이는 모델이 너무 복잡하여 노이즈나
에러에까지 잘 들어맞는 경우이다. 이를 해결하기 위해서는 좀 더 간단한 모델을 사용하거나 알고리즘을 그대로 사용하되 `regularization`
항목을 추가하는 것이 좋다. 이경우 정규화 항목은 조금 덜 복잡한 모델을 만드는 역할을 한다.

## Bias VS. Variance

>> 바이어스는 학습자가 같은 오류를 지속적으로 하려는 경향이다. 배어리언스는 실제 신호와는 관계없는 무작위의 것을 배우려는 경향이다.

주어진 훈련 셋은 $ s = \{(\vec{x_1}, t_1), \ldots, (\vec{x_n}, t_n)\} $ 으로 표현할 수 있고 머신 러닝 알고리즘은
모델 F를 생성하게 된다. 그러면 테스트 샘플 $\vec{x_k}$에 대해서 모델은 예측 $y_k = F(\vec{x_k})$을 하게 된다. 이 결과에
대해 손실 함수 $L(F(\vec{x_i}), t_i)$을 정의할 수 있는데, 실제 값과 예측값의 차이로 정의할 수 있다. 회귀 문제의 경우 자주
쓰이는 손실 함수는 **Squre Error**이다.

>> 주어진 손실 함수 L과 훈련 집합 $S = {s_1, s_2, \ldots, s_n}$에서 중심 예측값은 $y_m = argmin_{y'} E_s(L(y, y'))$
>> 으로 정의 된다. 이 값은 주어진 모델에 대해 평균 기대값으로 해석될 수 있다.

>> 주어진 샘플 $(\vec{x_i}, t_i)$에 대해 모델의 바이어스는 $B(\vec{x_i}) = L(y_m, t_i)$로 정의할 수 있는데, 여기서
>> $y_m$은 중심 예측값이고, $t_i$는 실제 값이고, $L$은 손실 함수이다.

>> 주어진 샘플 $(\vec{x_i}, t_i)$에 대해 모델의 배어리언스는 $V(\vec{x_i}) = E_s(L(y_m, y))$로 정의할 수 있는데, 여기서
>> $y_m$은 중심 예측값이고, $y$는 실제 값이고, $L$은 손실 함수이며, 훈련 집합 $s\in S$에 대해 $E_s$는 평균함수 이다.

![bias_variance_relation](https://assets.leetcode.com/uploads/2019/02/10/card_bias_variance.png)

학습자가 생성한 모델의 복잡도가 증가함에 따라 바이어스는 감소하고 베어리언스는 증가하게 된다.

## Why Machine Learning?

우리는 왜 기계 학습이 필요한가? 우선 기계 학습 알고리즘이 없이는 일상 생활을 할 수 없다. 페이스북의 경우 서비스의 모든 영역에
걸쳐 기계학습을 사용하고 있다. 예를 들어 이야기의 랭킹은 ML로 결정되어 진다. 누가 어디에 광고를 개제하는지도 기계학습으로
결정되어 진다. 또한 사진 비디오, 사람 찾기등의 서치 엔진도 ML로 구현되어 있다.

ML의 중요한 차이점 중의 하나는 데이터와 모델을 분리시켜 여러가지 비지니스 상황에 따라 다른 모델을 사용할 수 있다는 점이다.
이러한 분리에 따라 ML 모델은 여러가지 문제들을 좀 더 유연하게, 자동화된 방법으로 해결할 수 있게 된다.

## ML, Silver Bullet?

>> 인간과 같이 ML 모델들도 실수를 한다.

이미지 넷의 경우 2018년 현재 괜찮은 모델들은 대략 80%의 정확도를 가지고 있지, 100%의 정확도를 얻지 못한다. 따라서
알고리즘의 정확성이 중요한 경우 ML 모델을 도입하는 결정에 대해 신중해야 한다.

만약 모델의 문제가 발생한다면 일반적인 소프트웨어와 같이 문제를 하나 하나 해결하면 되지 않느냐고 생각할 수 있다. 그러나
다음과 같은 이유로 그렇게 할 수 없다. 1) 일반적으로 ML 모델을 직접적으로 수정하지 않는다. 따라서 모델을 발전시키기 위해서는
데이터나 알고리즘을 향상시키지 모델 자체를 수정하지 않는다. 2) 설사 만들어진 모델을 직접적으로 수정할 수 있다 하더라도,
다른 경우의 샘플 결과에 영향을 주지 않으면서 오류를 일으키는 샘플들만 수정하기 위해서는 어떻게 모델을 수정할 수 있을지가
알려져 있지 않다. 따라서 모델을 향상시키는 것은 전체적인 관점에서 접근해야 하지, 각각의 경우에 따라 일부분만 수정하는
식으로 할 수 없다.
